/**
 * NOTE (memory-curator.js):
 * Purpose: Hybrid curation system (rules + OpenAI GPT-4.1 nano) to validate and refine memories for LTM storage.
 * Controls: Impact score >0.7 required, forbidden content blocked, category validation, content refinement.
 * Behavior: curate() ‚Üí hard rules check ‚Üí AI scoring ‚Üí compress if needed ‚Üí return curation result.
 * Integration notes: Uses hard-rules.js, memory-compressor.js, relevance-calculator.js, and OpenAI GPT-4.1 nano.
 */

const { getCategoryDefinition } = require('./category-definitions');

const hardRules = require('../shared/hard-rules');
const memoryCompressor = require('../shared/memory-compressor');
const relevanceCalculator = require('./relevance-calculator');
const { IMPACT_THRESHOLDS, LTM_CATEGORIES } = require('../shared/memory-types');
const { callOpenAI, callOpenAIJSON } = require('../../../config/openai-config');

/**
 * Curate memory for LTM storage
 * @param {string} content - Memory content
 * @param {string} category - Memory category
 * @param {object} context - Additional context
 * @returns {Promise<object>} - Curation result
 */
async function curate(content, category, context = {}) {
  console.log('[Curator] üöÄ IN√çCIO - Curadoria de mem√≥ria');
  console.log('[Curator] üìã Entrada:', {
    category,
    contentLength: content?.length || 0,
    content: content?.substring(0, 100) + '...',
    context
  });
  
  // Step 1: Hard rules validation
  console.log('[Curator] üîí Step 1 - Validando conte√∫do proibido...');
  const forbidden = hardRules.containsForbiddenContent(content);
  if (forbidden.found) {
    console.log('[Curator] ‚ùå REJEITADO - Conte√∫do proibido detectado:', forbidden.type);
    return {
      accepted: false,
      reason: `Forbidden content detected: ${forbidden.type}`,
      content: null,
      impactScore: 0
    };
  }
  console.log('[Curator] ‚úÖ Step 1 - Nenhum conte√∫do proibido');

  // Step 2: Category validation
  console.log('[Curator] üìä Step 2 - Validando categoria:', category);
  if (!Object.values(LTM_CATEGORIES).includes(category)) {
    console.log('[Curator] ‚ùå REJEITADO - Categoria inv√°lida:', category);
    return {
      accepted: false,
      reason: `Invalid category: ${category}`,
      content: null,
      impactScore: 0
    };
  }
  console.log('[Curator] ‚úÖ Step 2 - Categoria v√°lida');

  // Step 3: Suitability check
  console.log('[Curator] ‚úÖ Step 3 - Verificando adequa√ß√£o para LTM...');
  if (!hardRules.isSuitableForLTM(content)) {
    console.log('[Curator] ‚ùå REJEITADO - Conte√∫do n√£o adequado para LTM');
    return {
      accepted: false,
      reason: 'Content not suitable for long-term memory',
      content: null,
      impactScore: 0
    };
  }
  console.log('[Curator] ‚úÖ Step 3 - Conte√∫do adequado para LTM');

  // Step 4: Calculate impact score
  console.log('[Curator] üéØ Step 4 - Calculando impact score...');
  const impactScore = await relevanceCalculator.calculate(content, {
    category,
    ...context
  });
  console.log('[Curator] üìä Impact Score calculado:', impactScore.toFixed(2));

  if (impactScore < IMPACT_THRESHOLDS.MIN_FOR_LTM) {
    console.log('[Curator] ‚ùå REJEITADO - Impact score muito baixo:', {
      score: impactScore.toFixed(2),
      min: IMPACT_THRESHOLDS.MIN_FOR_LTM
    });
    return {
      accepted: false,
      reason: `Impact score too low: ${impactScore.toFixed(2)} < ${IMPACT_THRESHOLDS.MIN_FOR_LTM}`,
      content: null,
      impactScore
    };
  }
  console.log('[Curator] ‚úÖ Step 4 - Impact score aceit√°vel');

  // Step 5: Refine content with LLM
  console.log('[Curator] ü§ñ Step 5 - Refinando conte√∫do com LLM...');
  let refinedContent = content;
  
  try {
    refinedContent = await refineWithLLM(content, category, impactScore);
    console.log('[Curator] ‚úÖ Step 5 - Conte√∫do refinado com sucesso');
    console.log('[Curator] üìù Antes:', content.substring(0, 100) + '...');
    console.log('[Curator] üìù Depois:', refinedContent.substring(0, 100) + '...');
  } catch (error) {
    console.warn('[Curator] ‚ö†Ô∏è Step 5 - Refinamento LLM falhou, usando original:', error.message);
  }

  // Step 6: Compress if too verbose
  const wordCount = refinedContent.split(/\s+/).length;
  console.log('[Curator] üìä Step 6 - Verificando tamanho:', wordCount, 'palavras');
  if (wordCount > 60) {
    console.log('[Curator] ‚úèÔ∏è Step 6 - Comprimindo conte√∫do (>60 palavras)...');
    try {
      refinedContent = await memoryCompressor.compress(refinedContent, { targetWords: 40 });
      console.log('[Curator] ‚úÖ Conte√∫do comprimido:', refinedContent.split(/\s+/).length, 'palavras');
    } catch (error) {
      console.warn('[Curator] ‚ö†Ô∏è Compress√£o falhou:', error.message);
    }
  } else {
    console.log('[Curator] ‚úÖ Step 6 - Tamanho adequado, n√£o precisa comprimir');
  }

  console.log('[Curator] ‚úÖ FIM - Mem√≥ria ACEITA');
  console.log('[Curator] üìä Resultado final:', {
    accepted: true,
    impactScore: impactScore.toFixed(2),
    wordCount: refinedContent.split(/\s+/).length,
    content: refinedContent
  });

  return {
    accepted: true,
    reason: 'Memory accepted for LTM',
    content: refinedContent,
    impactScore
  };
}

/**
 * Refine content with DeepSeek AI
 * @param {string} content - Original content
 * @param {string} category - Memory category
 * @param {number} impactScore - Impact score
 * @returns {Promise<string>} - Refined content
 */
async function refineWithLLM(content, category, impactScore) {
  console.log('[Curator.LLM] ü§ñ Chamando OpenAI para refinamento...');
  console.log('[Curator.LLM] üìä Par√¢metros:', { category, impactScore: impactScore.toFixed(2) });
  
  try {
    const systemPrompt = `You are a memory curator for a financial investment system.
Refine memories for long-term storage by keeping only the most essential and impactful information.

Guidelines:
- Preserve key facts, preferences, and strategic information
- Remove noise, redundancy, and temporary details
- Keep actionable insights and patterns
- Maintain clarity and specificity
- Identify event date from context (or use today's date if unclear)
- Memory MUST start with "Em DD/MM/YYYY, " prefix
- Maximum 60 words (including date prefix)`;

    const userPrompt = `Refine this memory for long-term storage:

Category: ${category}
Impact Score: ${impactScore.toFixed(2)}
Original: ${content}

MANDATORY FORMAT:
- Start with "Em DD/MM/YYYY, " where date is the event date (extract from context or use today)
- Follow with refined content
- Total max 60 words

Return refined version:`;

    console.log('[Curator.LLM] üì§ Enviando para OpenAI...');
    const refined = await callOpenAI(systemPrompt, userPrompt, {
      max_tokens: 200,
      temperature: 0.3 // Low temperature for consistency
    });

    console.log('[Curator.LLM] ‚úÖ Resposta recebida da OpenAI');
    console.log('[Curator.LLM] üìä Mudan√ßa de tamanho:', content.length, '‚Üí', refined.length, 'chars');
    console.log('[Curator.LLM] üìù Conte√∫do refinado:', refined);
    return refined;

  } catch (error) {
    console.error('[Curator.LLM] ‚ùå OpenAI refinement failed:', error.message);
    return content; // Fallback to original
  }
}

/**
 * Extract high-impact information from episodic memory using AI
 * @param {object} episodicData - Episodic memory data
 * @returns {Promise<Array>} - Candidate memories
 */
async function extractHighImpact(episodicData) {
  const { getCategoryDefinition, getAllCategories } = require('./category-definitions');
  const userName = episodicData.userName || 'Usu√°rio';
  try {
     const systemPrompt = `Voc√™ √© um extrator de mem√≥rias de longo prazo para sistema financeiro.
Analise a mem√≥ria epis√≥dica e extraia informa√ß√µes de ALTO IMPACTO para armazenamento permanente.

IMPORTANTE: Use sempre o NOME DO USU√ÅRIO ao formular mem√≥rias.
NOME DO USU√ÅRIO: ${userName}

Ao formular mem√≥rias, sempre use "${userName}" ao inv√©s de "o usu√°rio" ou "ele/ela".

CATEGORIAS DISPON√çVEIS:
${getAllCategories().map(cat => {
  const def = getCategoryDefinition(cat);
  return `- ${cat}: ${def.description}`;
}).join('\n')}

Para cada informa√ß√£o valiosa encontrada:
1. Identifique a categoria mais apropriada
2. Formule a mem√≥ria usando o NOME do usu√°rio (${userName})
3. Seja espec√≠fico com valores e datas
4. Avalie o impact score (0.0-1.0)

Extraia apenas informa√ß√µes que:
- Sejam duradouras e relevantes
- Tenham impacto em decis√µes futuras
- Sejam espec√≠ficas e acion√°veis
- Mere√ßam armazenamento permanente (score >= 0.7)`;

    const userPrompt = `Extract high-impact information from this episodic memory:

${JSON.stringify(episodicData, null, 2)}

Return JSON array of candidates com o nome "${userName}":
[
  {
    "content": "<extracted information usando '${userName}'>",
    "category": "<uma das categorias listadas acima>",
    "reasoning": "<why this is high-impact>"
  }
]`;

    const result = await callOpenAIJSON(systemPrompt, userPrompt, {
      max_tokens: 800,
      temperature: 0.4
    });

    const candidates = [];

    // Validate and score each candidate
    for (const candidate of (result || [])) {
      const { content, category, reasoning } = candidate;
      
      if (!content || !category) continue;

      const impactScore = await relevanceCalculator.calculate(content, { 
        source: 'episodic',
        category 
      });

      if (impactScore >= IMPACT_THRESHOLDS.MIN_FOR_LTM) {
        candidates.push({
          content,
          category,
          impactScore,
          reasoning
        });
        console.log(`[Curator] Extracted candidate (score ${impactScore.toFixed(2)}): ${reasoning}`);
      }
    }

    return candidates;

  } catch (error) {
    console.error('[Curator] AI extraction failed, using fallback:', error.message);
    return extractHighImpactFallback(episodicData);
  }
}

/**
 * Fallback extraction using simple heuristics
 * @param {object} episodicData - Episodic memory data
 * @returns {Promise<Array>} - Candidate memories
 */
async function extractHighImpactFallback(episodicData) {
  const candidates = [];

  if (typeof episodicData === 'object') {
    const keys = ['preferences', 'goals', 'patterns', 'decisions', 'learnings'];
    
    for (const key of keys) {
      if (episodicData[key]) {
        const content = typeof episodicData[key] === 'string' 
          ? episodicData[key] 
          : JSON.stringify(episodicData[key]);

        const impactScore = await relevanceCalculator.calculate(content, { source: 'episodic' });
        
        if (impactScore >= IMPACT_THRESHOLDS.MIN_FOR_LTM) {
          candidates.push({
            content,
            category: mapKeyToCategory(key),
            impactScore
          });
        }
      }
    }
  }

  return candidates;
}

/**
 * Map episodic key to LTM category
 * @param {string} key - Episodic key
 * @returns {string} - LTM category
 */
function mapKeyToCategory(key) {
  const mapping = {
    // Map common episodic keys to the canonical LTM categories defined
    // in `shared/memory-types.js` / `category-definitions.js`.
    preferences: LTM_CATEGORIES.RELACAO_PLATAFORMA,
    goals: LTM_CATEGORIES.OBJETIVOS_METAS,
    patterns: LTM_CATEGORIES.COMPORTAMENTO_GASTOS,
    decisions: LTM_CATEGORIES.PLANEJAMENTO_FUTURO,
    learnings: LTM_CATEGORIES.CONHECIMENTO_FINANCEIRO
  };

  // Default to a safe, broad category for generic preferences
  return mapping[key] || LTM_CATEGORIES.RELACAO_PLATAFORMA;
}

/**
 * Batch curate multiple memories
 * @param {Array} memories - Array of {content, category, context}
 * @returns {Promise<Array>} - Curation results
 */
async function batchCurate(memories) {
  const results = [];

  for (const memory of memories) {
    const result = await curate(memory.content, memory.category, memory.context);
    results.push({
      ...memory,
      curationResult: result
    });
  }

  return results;
}

module.exports = {
  curate,
  extractHighImpact,
  batchCurate
};
