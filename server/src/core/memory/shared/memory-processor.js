/**
 * NOTE (memory-processor.js):
 * Purpose: Processa mem√≥rias em background ap√≥s resposta da IA.
 * Controls: Classifica√ß√£o paralela entre working, epis√≥dica e long-term.
 * Behavior: Executado ap√≥s resposta ao usu√°rio, n√£o bloqueia intera√ß√£o.
 * Integration notes: Chamado por serverAgent ap√≥s JuniorAgent responder.
 */

const workingMemory = require('../working/working-memory');
const episodicMemory = require('../episodic/episodic-memory');
const longTermMemory = require('../longTerm/long-term-memory');
const { callOpenAIJSON } = require('../../../config/openai-config');
const { LTM_CATEGORIES } = require('./memory-types');
const patternClassifier = require('./pattern-classifier');

/**
 * Processar mem√≥rias ap√≥s intera√ß√£o
 * @param {object} context - Contexto da intera√ß√£o
 * @param {string} context.sessionId - ID da sess√£o
 * @param {string} context.userId - ID do usu√°rio
 * @param {string} context.chatId - ID do chat
 * @param {string} context.userMessage - Mensagem do usu√°rio
 * @param {string} context.aiResponse - Resposta da IA
 * @param {array} context.history - Hist√≥rico do chat
 * @param {string} context.userName - Nome do usu√°rio (para LTM personalizada)
 * @returns {Promise<object>} - Resultado do processamento
 */
async function processMemories(context) {
  const { sessionId, userId, chatId, userMessage, aiResponse, history, userName } = context;
  
  console.log('[MemoryProcessor] üöÄ IN√çCIO - Processamento de mem√≥rias iniciado');
  console.log('[MemoryProcessor] üìä Contexto:', {
    sessionId,
    chatId,
    userId,
    userName: userName || 'n√£o fornecido',
    userMessageLength: userMessage?.length || 0,
    aiResponseLength: aiResponse?.length || 0,
    historyLength: history?.length || 0
  });
  console.log('[MemoryProcessor] üí¨ Mensagem do usu√°rio:', userMessage);
  console.log('[MemoryProcessor] ü§ñ Resposta da IA:', aiResponse.substring(0, 200) + '...');
  
  try {
    // Classificar intera√ß√£o usando PADR√ïES INTELIGENTES (sem IA, economiza ~1800 tokens)
    console.log('[MemoryProcessor] üß† Usando pattern matching (sem IA)...');
    const classification = patternClassifier.classifyInteraction({
      userMessage,
      aiResponse,
      history,
      userName: userName || 'o usu√°rio'
    });
    
    console.log('[MemoryProcessor] ‚úÖ Classifica√ß√£o (via patterns) conclu√≠da');
    console.log('[MemoryProcessor] üìù Working items:', classification.working.length);
    console.log('[MemoryProcessor] üìñ Episodic:', JSON.stringify(classification.episodic, null, 2));
    console.log('[MemoryProcessor] üíæ Long-term candidates:', classification.longTerm.length);
    console.log('[MemoryProcessor] üîç DETALHES DA CLASSIFICA√á√ÉO:', {
      working: classification.working,
      episodic: classification.episodic,
      longTerm: classification.longTerm
    });
    
    if (classification.working.length > 0) {
      console.log('[MemoryProcessor] üîç Working Memory detalhes:', classification.working);
    }
    if (classification.longTerm.length > 0) {
      console.log('[MemoryProcessor] üîç Long-term candidates detalhes:', classification.longTerm);
    }
    
    // Processar em paralelo (mais r√°pido)
    const promises = [];
    
    // Working Memory - sempre processa se houver dados relevantes
    if (classification.working && classification.working.length > 0) {
      console.log('[MemoryProcessor] üîß Adicionando Working Memory ao processamento:', classification.working.length, 'items');
      promises.push(
        processWorkingMemory(sessionId, userId, classification.working)
      );
    } else {
      console.log('[MemoryProcessor] ‚è≠Ô∏è Nenhum item para Working Memory');
    }
    
    // Episodic Memory - armazena contexto da conversa
    if (classification.episodic) {
      console.log('[MemoryProcessor] üìñ Adicionando Episodic Memory ao processamento');
      promises.push(
        processEpisodicMemory(chatId, userId, classification.episodic)
      );
    } else {
      console.log('[MemoryProcessor] ‚è≠Ô∏è Nenhum dado para Episodic Memory');
    }
    
    // Long-Term Memory - promove informa√ß√µes de alto impacto
    if (classification.longTerm && classification.longTerm.length > 0) {
      console.log('[MemoryProcessor] üíæ Adicionando Long-Term Memory ao processamento:', classification.longTerm.length, 'candidates');
      promises.push(
        processLongTermMemory(userId, chatId, classification.longTerm)
      );
    } else {
      console.log('[MemoryProcessor] ‚è≠Ô∏è Nenhum candidate para Long-Term Memory');
    }
    
    const results = await Promise.allSettled(promises);
    
    // Log resultados
    results.forEach((result, idx) => {
      if (result.status === 'fulfilled') {
        console.log(`[MemoryProcessor] Processamento ${idx + 1} conclu√≠do:`, result.value);
      } else {
        console.error(`[MemoryProcessor] Processamento ${idx + 1} falhou:`, result.reason);
      }
    });
    
    const finalResult = {
      success: true,
      classification,
      results: results.map(r => r.status === 'fulfilled' ? r.value : { error: r.reason.message })
    };

    console.log('[MemoryProcessor] ‚úÖ FIM - Processamento conclu√≠do');
    console.log('[MemoryProcessor] üìä Estat√≠sticas:', {
      success: true,
      workingItemsProcessed: classification.working?.length || 0,
      episodicProcessed: classification.episodic ? 'sim' : 'n√£o',
      longTermCandidates: classification.longTerm?.length || 0,
      resultsCount: results.length,
      successfulResults: results.filter(r => r.status === 'fulfilled').length,
      failedResults: results.filter(r => r.status === 'rejected').length
    });
    console.log('[MemoryProcessor] üìã Resultado detalhado:', JSON.stringify(finalResult, null, 2));

    return finalResult;
    
  } catch (error) {
    console.error('[MemoryProcessor] ‚ùå Erro no processamento:', error);
    throw error;
  }
}

/**
 * Classificar intera√ß√£o usando IA (DEPRECADO - usar pattern-classifier.js)
 * NOTA: Esta fun√ß√£o est√° desabilitada para economizar tokens.
 * Use patternClassifier.classifyInteraction() ao inv√©s.
 * Mantida apenas para refer√™ncia/rollback se necess√°rio.
 * @param {object} interaction - Dados da intera√ß√£o
 * @param {string} interaction.userName - Nome do usu√°rio
 * @returns {Promise<object>} - Classifica√ß√£o { working: [], episodic: {}, longTerm: [] }
 */
async function classifyInteraction_AI_DEPRECATED({ userMessage, aiResponse, history, userName = 'o usu√°rio' }) {
  const systemPrompt = `Voc√™ √© um classificador de mem√≥rias para sistema financeiro.
Analise a intera√ß√£o usu√°rio-IA e classifique informa√ß√µes para armazenamento.

TIPOS DE MEM√ìRIA:

1. WORKING MEMORY (tempor√°ria, sess√£o atual):
   - C√°lculos intermedi√°rios
   - Par√¢metros de a√ß√£o atual
   - Contexto imediato de racioc√≠nio
   - Dados que s√≥ importam AGORA

2. EPISODIC MEMORY (contexto do chat):
   - Prefer√™ncias mencionadas na conversa
   - Decis√µes tomadas neste chat
   - Contexto espec√≠fico desta intera√ß√£o
   - Informa√ß√µes que podem ser √∫teis nas pr√≥ximas mensagens DESTE chat
   - Use PRIMEIRA PESSOA ao descrever suas respostas: "EU respondi" ao inv√©s de "a IA respondeu"

3. LONG-TERM MEMORY (perfil permanente):
   - Informa√ß√µes duradouras sobre o usu√°rio
   - Padr√µes comportamentais identificados
   - Decis√µes estrat√©gicas importantes
   - Dados que devem ser lembrados SEMPRE
   - SEMPRE use o nome do usu√°rio (${userName}) ao formular mem√≥rias long-term

CATEGORIAS LONG-TERM (use exatamente estes nomes):
${Object.values(LTM_CATEGORIES).map(cat => `- ${cat}`).join('\n')}

REGRAS:
- Mesma informa√ß√£o pode ir para m√∫ltiplas mem√≥rias
- Working: apenas se c√°lculo/racioc√≠nio precisa ser continuado
- Episodic: sempre que houver contexto relevante para o chat
- Long-term: apenas informa√ß√µes de ALTO IMPACTO e duradouras
- Long-term: SEMPRE use "${userName}" ao inv√©s de "o usu√°rio"`;

  const userPrompt = `Classifique esta intera√ß√£o:

MENSAGEM DO USU√ÅRIO:
${userMessage}

RESPOSTA DA IA:
${aiResponse}

HIST√ìRICO (√∫ltimas 3 mensagens):
${JSON.stringify(history?.slice(-3) || [], null, 2)}

Retorne JSON:
{
  "working": [
    { "key": "nome_variavel", "value": "valor", "reason": "por que √© working" }
  ],
  "episodic": {
    "contexto_conversa": "resumo do que aconteceu (use primeira pessoa: 'EU respondi' ao inv√©s de 'a IA respondeu')",
    "preferencias_mencionadas": "prefer√™ncias citadas",
    "decisoes_tomadas": "decis√µes do usu√°rio"
  },
  "longTerm": [
    {
      "content": "informa√ß√£o usando o nome ${userName}",
      "category": "uma das categorias v√°lidas",
      "reason": "por que √© long-term"
    }
  ]
}

Se n√£o houver dados para algum tipo, retorne array/objeto vazio.`;

  try {
    const result = await callOpenAIJSON(systemPrompt, userPrompt, {
      max_tokens: 1000,
      temperature: 0.3
    });
    
    return {
      working: result.working || [],
      episodic: result.episodic || {},
      longTerm: result.longTerm || []
    };
    
  } catch (error) {
    console.error('[MemoryProcessor] Erro na classifica√ß√£o:', error);
    // Fallback: classifica√ß√£o vazia
    return { working: [], episodic: {}, longTerm: [] };
  }
}

/**
 * Processar Working Memory
 */
async function processWorkingMemory(sessionId, userId, workingData) {
  console.log('[Working] üöÄ IN√çCIO - Processando Working Memory');
  console.log('[Working] üìä Total de itens:', workingData.length);
  console.log('[Working] üì¶ Dados:', workingData);
  
  const results = [];
  for (const item of workingData) {
    try {
      console.log('[Working] üíæ Salvando item:', { key: item.key, value: item.value, reason: item.reason });
      await workingMemory.set(sessionId, item.key, item.value, false, userId);
      console.log('[Working] ‚úÖ Item salvo com sucesso:', item.key);
      results.push({ key: item.key, status: 'stored' });
    } catch (error) {
      console.error('[Working] ‚ùå Erro ao armazenar:', item.key, error.message);
      results.push({ key: item.key, status: 'error', error: error.message });
    }
  }
  
  console.log('[Working] ‚úÖ FIM - Working Memory processada');
  console.log('[Working] üìä Resultados:', results);
  return { type: 'working', results };
}

/**
 * Processar Episodic Memory
 */
async function processEpisodicMemory(chatId, userId, episodicData) {
  console.log('[Episodic] üöÄ IN√çCIO - Processando Episodic Memory');
  console.log('[Episodic] üìä Chat ID:', chatId);
  console.log('[Episodic] üì¶ Dados epis√≥dicos:', episodicData);
  
  try {
    // Verifica se chat j√° tem mem√≥ria
    console.log('[Episodic] üîç Verificando se chat j√° possui mem√≥ria...');
    const existing = await episodicMemory.get(chatId);
    
    if (existing) {
      console.log('[Episodic] ‚úèÔ∏è Chat possui mem√≥ria existente, atualizando...');
      console.log('[Episodic] üìù Mem√≥ria atual:', existing.episodicMemory);
      // Atualiza mem√≥ria existente
      await episodicMemory.update(chatId, episodicData, {
        merge: true,
        autoCompress: true
      });
      console.log('[Episodic] ‚úÖ Mem√≥ria atualizada com sucesso');
      return { type: 'episodic', status: 'updated', chatId };
    } else {
      console.log('[Episodic] üÜï Chat sem mem√≥ria, criando nova...');
      // Cria nova mem√≥ria para o chat
      await episodicMemory.create(chatId, userId, episodicData);
      console.log('[Episodic] ‚úÖ Nova mem√≥ria criada com sucesso');
      return { type: 'episodic', status: 'created', chatId };
    }
    
  } catch (error) {
    console.error('[Episodic] ‚ùå Erro no processamento:', error.message);
    return { type: 'episodic', status: 'error', error: error.message };
  }
}

/**
 * Processar Long-Term Memory
 */
async function processLongTermMemory(userId, chatId, longTermData) {
  console.log('[LongTerm] üöÄ IN√çCIO - Processando Long-Term Memory');
  console.log('[LongTerm] üìä Total de candidatos:', longTermData.length);
  console.log('[LongTerm] üì¶ Candidatos:', longTermData);
  
  const results = [];
  for (const item of longTermData) {
    console.log('[LongTerm] üéØ Propondo mem√≥ria:', {
      category: item.category,
      content: item.content.substring(0, 100) + '...',
      reason: item.reason
    });
    
    try {
      const stored = await longTermMemory.propose(
        userId,
        item.content,
        item.category,
        [chatId]
      );
      
      if (stored) {
        console.log('[LongTerm] ‚úÖ Mem√≥ria ACEITA e armazenada');
        console.log('[LongTerm] üìä Impact Score:', stored.impactScore);
        results.push({ 
          category: item.category, 
          status: 'accepted',
          impactScore: stored.impactScore 
        });
      } else {
        console.log('[LongTerm] ‚ùå Mem√≥ria REJEITADA pela curadoria');
        results.push({ 
          category: item.category, 
          status: 'rejected',
          reason: 'N√£o passou na curadoria'
        });
      }
      
    } catch (error) {
      console.error('[LongTerm] ‚ùå Erro ao propor mem√≥ria:', error.message);
      results.push({ 
        category: item.category, 
        status: 'error', 
        error: error.message 
      });
    }
  }
  
  console.log('[LongTerm] ‚úÖ FIM - Long-Term Memory processada');
  console.log('[LongTerm] üìä Resultados:', results);
  return { type: 'longTerm', results };
}

module.exports = {
  processMemories,
  classifyInteraction: patternClassifier.classifyInteraction
  // classifyInteraction_AI_DEPRECATED dispon√≠vel internamente para rollback se necess√°rio
};