/**
 * NOTE (memory-processor.js):
 * Purpose: Processa mem√≥rias em background ap√≥s resposta da IA.
 * Controls: Classifica√ß√£o paralela entre working, epis√≥dica e long-term.
 * Behavior: Executado ap√≥s resposta ao usu√°rio, n√£o bloqueia intera√ß√£o.
 * Integration notes: Chamado por serverAgent ap√≥s JuniorAgent responder.
 */

const workingMemory = require('../working/working-memory');
const episodicMemory = require('../episodic/episodic-memory');
const longTermMemory = require('../longTerm/long-term-memory');
const { callOpenAIJSON } = require('../../../config/openai-config');
const { LTM_CATEGORIES } = require('./memory-types');

/**
 * Processar mem√≥rias ap√≥s intera√ß√£o
 * @param {object} context - Contexto da intera√ß√£o
 * @param {string} context.sessionId - ID da sess√£o
 * @param {string} context.userId - ID do usu√°rio
 * @param {string} context.chatId - ID do chat
 * @param {string} context.userMessage - Mensagem do usu√°rio
 * @param {string} context.aiResponse - Resposta da IA
 * @param {array} context.history - Hist√≥rico do chat
 * @param {string} context.userName - Nome do usu√°rio (para LTM personalizada)
 * @returns {Promise<object>} - Resultado do processamento
 */
async function processMemories(context) {
  const { sessionId, userId, chatId, userMessage, aiResponse, history, userName } = context;
  
  console.log('[MemoryProcessor] üöÄ IN√çCIO - Processamento de mem√≥rias iniciado', {
    sessionId,
    chatId,
    userId,
    userName: userName || 'n√£o fornecido',
    userMessageLength: userMessage?.length || 0,
    aiResponseLength: aiResponse?.length || 0,
    historyLength: history?.length || 0
  });
  
  try {
    // Classificar intera√ß√£o
    const classification = await classifyInteraction({
      userMessage,
      aiResponse,
      history,
      userName: userName || 'o usu√°rio'
    });
    
    console.log('[MemoryProcessor] Classifica√ß√£o:', classification);
    
    // Processar em paralelo (mais r√°pido)
    const promises = [];
    
    // Working Memory - sempre processa se houver dados relevantes
    if (classification.working && classification.working.length > 0) {
      promises.push(
        processWorkingMemory(sessionId, userId, classification.working)
      );
    }
    
    // Episodic Memory - armazena contexto da conversa
    if (classification.episodic) {
      promises.push(
        processEpisodicMemory(chatId, userId, classification.episodic)
      );
    }
    
    // Long-Term Memory - promove informa√ß√µes de alto impacto
    if (classification.longTerm && classification.longTerm.length > 0) {
      promises.push(
        processLongTermMemory(userId, chatId, classification.longTerm)
      );
    }
    
    const results = await Promise.allSettled(promises);
    
    // Log resultados
    results.forEach((result, idx) => {
      if (result.status === 'fulfilled') {
        console.log(`[MemoryProcessor] Processamento ${idx + 1} conclu√≠do:`, result.value);
      } else {
        console.error(`[MemoryProcessor] Processamento ${idx + 1} falhou:`, result.reason);
      }
    });
    
    const finalResult = {
      success: true,
      classification,
      results: results.map(r => r.status === 'fulfilled' ? r.value : { error: r.reason.message })
    };

    console.log('[MemoryProcessor] ‚úÖ FIM - Processamento conclu√≠do', {
      success: true,
      workingItemsProcessed: classification.working?.length || 0,
      episodicProcessed: classification.episodic ? 'sim' : 'n√£o',
      longTermCandidates: classification.longTerm?.length || 0,
      resultsCount: results.length,
      successfulResults: results.filter(r => r.status === 'fulfilled').length,
      failedResults: results.filter(r => r.status === 'rejected').length
    });

    return finalResult;
    
  } catch (error) {
    console.error('[MemoryProcessor] ‚ùå Erro no processamento:', error);
    throw error;
  }
}

/**
 * Classificar intera√ß√£o usando IA
 * @param {object} interaction - Dados da intera√ß√£o
 * @param {string} interaction.userName - Nome do usu√°rio
 * @returns {Promise<object>} - Classifica√ß√£o { working: [], episodic: {}, longTerm: [] }
 */
async function classifyInteraction({ userMessage, aiResponse, history, userName = 'o usu√°rio' }) {
  const systemPrompt = `Voc√™ √© um classificador de mem√≥rias para sistema financeiro.
Analise a intera√ß√£o usu√°rio-IA e classifique informa√ß√µes para armazenamento.

TIPOS DE MEM√ìRIA:

1. WORKING MEMORY (tempor√°ria, sess√£o atual):
   - C√°lculos intermedi√°rios
   - Par√¢metros de a√ß√£o atual
   - Contexto imediato de racioc√≠nio
   - Dados que s√≥ importam AGORA

2. EPISODIC MEMORY (contexto do chat):
   - Prefer√™ncias mencionadas na conversa
   - Decis√µes tomadas neste chat
   - Contexto espec√≠fico desta intera√ß√£o
   - Informa√ß√µes que podem ser √∫teis nas pr√≥ximas mensagens DESTE chat

3. LONG-TERM MEMORY (perfil permanente):
   - Informa√ß√µes duradouras sobre o usu√°rio
   - Padr√µes comportamentais identificados
   - Decis√µes estrat√©gicas importantes
   - Dados que devem ser lembrados SEMPRE
   - SEMPRE use o nome do usu√°rio (${userName}) ao formular mem√≥rias long-term

CATEGORIAS LONG-TERM (use exatamente estes nomes):
${Object.values(LTM_CATEGORIES).map(cat => `- ${cat}`).join('\n')}

REGRAS:
- Mesma informa√ß√£o pode ir para m√∫ltiplas mem√≥rias
- Working: apenas se c√°lculo/racioc√≠nio precisa ser continuado
- Episodic: sempre que houver contexto relevante para o chat
- Long-term: apenas informa√ß√µes de ALTO IMPACTO e duradouras
- Long-term: SEMPRE use "${userName}" ao inv√©s de "o usu√°rio"`;

  const userPrompt = `Classifique esta intera√ß√£o:

MENSAGEM DO USU√ÅRIO:
${userMessage}

RESPOSTA DA IA:
${aiResponse}

HIST√ìRICO (√∫ltimas 3 mensagens):
${JSON.stringify(history?.slice(-3) || [], null, 2)}

Retorne JSON:
{
  "working": [
    { "key": "nome_variavel", "value": "valor", "reason": "por que √© working" }
  ],
  "episodic": {
    "contexto_conversa": "resumo do que aconteceu",
    "preferencias_mencionadas": "prefer√™ncias citadas",
    "decisoes_tomadas": "decis√µes do usu√°rio"
  },
  "longTerm": [
    {
      "content": "informa√ß√£o usando o nome ${userName}",
      "category": "uma das categorias v√°lidas",
      "reason": "por que √© long-term"
    }
  ]
}

Se n√£o houver dados para algum tipo, retorne array/objeto vazio.`;

  try {
    const result = await callOpenAIJSON(systemPrompt, userPrompt, {
      max_tokens: 1000,
      temperature: 0.3
    });
    
    return {
      working: result.working || [],
      episodic: result.episodic || {},
      longTerm: result.longTerm || []
    };
    
  } catch (error) {
    console.error('[MemoryProcessor] Erro na classifica√ß√£o:', error);
    // Fallback: classifica√ß√£o vazia
    return { working: [], episodic: {}, longTerm: [] };
  }
}

/**
 * Processar Working Memory
 */
async function processWorkingMemory(sessionId, userId, workingData) {
  console.log(`[Working] Processando ${workingData.length} itens`);
  
  const results = [];
  for (const item of workingData) {
    try {
      await workingMemory.set(sessionId, item.key, item.value, false, userId);
      results.push({ key: item.key, status: 'stored' });
    } catch (error) {
      console.error(`[Working] Erro ao armazenar ${item.key}:`, error.message);
      results.push({ key: item.key, status: 'error', error: error.message });
    }
  }
  
  return { type: 'working', results };
}

/**
 * Processar Episodic Memory
 */
async function processEpisodicMemory(chatId, userId, episodicData) {
  console.log(`[Episodic] Processando para chat ${chatId}`);
  
  try {
    // Verifica se chat j√° tem mem√≥ria
    const existing = await episodicMemory.get(chatId);
    
    if (existing) {
      // Atualiza mem√≥ria existente
      await episodicMemory.update(chatId, episodicData, {
        merge: true,
        autoCompress: true
      });
      return { type: 'episodic', status: 'updated', chatId };
    } else {
      // Cria nova mem√≥ria para o chat
      await episodicMemory.create(chatId, userId, episodicData);
      return { type: 'episodic', status: 'created', chatId };
    }
    
  } catch (error) {
    console.error('[Episodic] Erro no processamento:', error.message);
    return { type: 'episodic', status: 'error', error: error.message };
  }
}

/**
 * Processar Long-Term Memory
 */
async function processLongTermMemory(userId, chatId, longTermData) {
  console.log(`[LongTerm] Processando ${longTermData.length} candidatos`);
  
  const results = [];
  for (const item of longTermData) {
    try {
      const stored = await longTermMemory.propose(
        userId,
        item.content,
        item.category,
        [chatId]
      );
      
      if (stored) {
        results.push({ 
          category: item.category, 
          status: 'accepted',
          impactScore: stored.impactScore 
        });
      } else {
        results.push({ 
          category: item.category, 
          status: 'rejected',
          reason: 'N√£o passou na curadoria'
        });
      }
      
    } catch (error) {
      console.error(`[LongTerm] Erro ao propor mem√≥ria:`, error.message);
      results.push({ 
        category: item.category, 
        status: 'error', 
        error: error.message 
      });
    }
  }
  
  return { type: 'longTerm', results };
}

module.exports = {
  processMemories,
  classifyInteraction
};