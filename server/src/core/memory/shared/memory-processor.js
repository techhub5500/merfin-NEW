/**
 * NOTE (memory-processor.js):
 * Purpose: Processa memÃ³rias em background apÃ³s resposta da IA.
 * Controls: ClassificaÃ§Ã£o paralela entre working, episÃ³dica e long-term.
 * Behavior: Executado apÃ³s resposta ao usuÃ¡rio, nÃ£o bloqueia interaÃ§Ã£o.
 * Integration notes: Chamado por serverAgent apÃ³s JuniorAgent responder.
 */

const workingMemory = require('../working/working-memory');
const episodicMemory = require('../episodic/episodic-memory');
const longTermMemory = require('../longTerm/long-term-memory');
const { callOpenAIJSON } = require('../../../config/openai-config');
const { LTM_CATEGORIES } = require('./memory-types');
const patternClassifier = require('./pattern-classifier');
const narrativeEngine = require('./narrative-engine');

/**
 * Processar memÃ³rias apÃ³s interaÃ§Ã£o
 * @param {object} context - Contexto da interaÃ§Ã£o
 * @param {string} context.sessionId - ID da sessÃ£o
 * @param {string} context.userId - ID do usuÃ¡rio
 * @param {string} context.chatId - ID do chat
 * @param {string} context.userMessage - Mensagem do usuÃ¡rio
 * @param {string} context.aiResponse - Resposta da IA
 * @param {array} context.history - HistÃ³rico do chat
 * @param {string} context.userName - Nome do usuÃ¡rio (para LTM personalizada)
 * @returns {Promise<object>} - Resultado do processamento
 */
async function processMemories(context) {
  const { sessionId, userId, chatId, userMessage, aiResponse, history, userName } = context;
  
  console.log('[MemoryProcessor] ğŸš€ INÃCIO - Processamento de memÃ³rias iniciado');
  console.log('[MemoryProcessor] ğŸ“Š Contexto:', {
    sessionId,
    chatId,
    userId,
    userName: userName || 'nÃ£o fornecido',
    userMessageLength: userMessage?.length || 0,
    aiResponseLength: aiResponse?.length || 0,
    historyLength: history?.length || 0
  });
  console.log('[MemoryProcessor] ğŸ’¬ Mensagem do usuÃ¡rio:', userMessage);
  console.log('[MemoryProcessor] ğŸ¤– Resposta da IA:', aiResponse.substring(0, 200) + '...');
  
  try {
    // Classificar interaÃ§Ã£o usando PADRÃ•ES INTELIGENTES (sem IA, economiza ~1800 tokens)
    console.log('[MemoryProcessor] ğŸ§  Usando pattern matching (sem IA)...');
    const classification = patternClassifier.classifyInteraction({
      userMessage,
      aiResponse,
      history,
      userName: userName || 'o usuÃ¡rio'
    });
    
    console.log('[MemoryProcessor] âœ… ClassificaÃ§Ã£o (via patterns) concluÃ­da');
    console.log('[MemoryProcessor] ğŸ“ Working items:', classification.working.length);
    console.log('[MemoryProcessor] ğŸ“– Episodic:', JSON.stringify(classification.episodic, null, 2));
    console.log('[MemoryProcessor] ğŸ’¾ Long-term candidates:', classification.longTerm.length);
    console.log('[MemoryProcessor] ğŸ” DETALHES DA CLASSIFICAÃ‡ÃƒO:', {
      working: classification.working,
      episodic: classification.episodic,
      longTerm: classification.longTerm
    });
    
    if (classification.working.length > 0) {
      console.log('[MemoryProcessor] ğŸ” Working Memory detalhes:', classification.working);
    }
    if (classification.longTerm.length > 0) {
      console.log('[MemoryProcessor] ğŸ” Long-term candidates detalhes:', classification.longTerm);
    }
    
    // Processar em paralelo (mais rÃ¡pido)
    const promises = [];
    
    // Working Memory - sempre processa se houver dados relevantes
    if (classification.working && classification.working.length > 0) {
      console.log('[MemoryProcessor] ğŸ”§ Adicionando Working Memory ao processamento:', classification.working.length, 'items');
      promises.push(
        processWorkingMemory(sessionId, userId, classification.working)
      );
    } else {
      console.log('[MemoryProcessor] â­ï¸ Nenhum item para Working Memory');
    }
    
    // Episodic Memory - armazena contexto da conversa com eventos estruturados
    if (classification.episodic) {
      console.log('[MemoryProcessor] ğŸ“– Adicionando Episodic Memory ao processamento');
      promises.push(
        processEpisodicMemory(chatId, userId, classification.episodic, {
          userMessage,
          aiResponse,
          history
        })
      );
    } else {
      console.log('[MemoryProcessor] â­ï¸ Nenhum dado para Episodic Memory');
    }
    
    // Long-Term Memory - promove informaÃ§Ãµes de alto impacto
    if (classification.longTerm && classification.longTerm.length > 0) {
      console.log('[MemoryProcessor] ğŸ’¾ Adicionando Long-Term Memory ao processamento:', classification.longTerm.length, 'candidates');
      promises.push(
        processLongTermMemory(userId, chatId, classification.longTerm)
      );
    } else {
      console.log('[MemoryProcessor] â­ï¸ Nenhum candidate para Long-Term Memory');
    }
    
    const results = await Promise.allSettled(promises);
    
    // Log resultados
    results.forEach((result, idx) => {
      if (result.status === 'fulfilled') {
        console.log(`[MemoryProcessor] Processamento ${idx + 1} concluÃ­do:`, result.value);
      } else {
        console.error(`[MemoryProcessor] Processamento ${idx + 1} falhou:`, result.reason);
      }
    });
    
    const finalResult = {
      success: true,
      classification,
      results: results.map(r => r.status === 'fulfilled' ? r.value : { error: r.reason.message })
    };

    console.log('[MemoryProcessor] âœ… FIM - Processamento concluÃ­do');
    console.log('[MemoryProcessor] ğŸ“Š EstatÃ­sticas:', {
      success: true,
      workingItemsProcessed: classification.working?.length || 0,
      episodicProcessed: classification.episodic ? 'sim' : 'nÃ£o',
      longTermCandidates: classification.longTerm?.length || 0,
      resultsCount: results.length,
      successfulResults: results.filter(r => r.status === 'fulfilled').length,
      failedResults: results.filter(r => r.status === 'rejected').length
    });
    console.log('[MemoryProcessor] ğŸ“‹ Resultado detalhado:', JSON.stringify(finalResult, null, 2));

    return finalResult;
    
  } catch (error) {
    console.error('[MemoryProcessor] âŒ Erro no processamento:', error);
    throw error;
  }
}

// (AI-based classification removed - deprecated implementation deleted)

/**
 * Processar Working Memory
 */
async function processWorkingMemory(sessionId, userId, workingData) {
  console.log('[Working] ğŸš€ INÃCIO - Processando Working Memory');
  console.log('[Working] ğŸ“Š Total de itens:', workingData.length);
  console.log('[Working] ğŸ“¦ Dados:', workingData);
  
  const results = [];
  for (const item of workingData) {
    try {
      console.log('[Working] ğŸ’¾ Salvando item:', { key: item.key, value: item.value, reason: item.reason });
      await workingMemory.set(sessionId, item.key, item.value, false, userId);
      console.log('[Working] âœ… Item salvo com sucesso:', item.key);
      results.push({ key: item.key, status: 'stored' });
    } catch (error) {
      console.error('[Working] âŒ Erro ao armazenar:', item.key, error.message);
      results.push({ key: item.key, status: 'error', error: error.message });
    }
  }
  
  console.log('[Working] âœ… FIM - Working Memory processada');
  console.log('[Working] ğŸ“Š Resultados:', results);
  return { type: 'working', results };
}

/**
 * Processar Episodic Memory com eventos estruturados e resumo narrativo
 */
async function processEpisodicMemory(chatId, userId, episodicData, rawInteraction) {
  console.log('[Episodic] ğŸš€ INÃCIO - Processando Episodic Memory');
  console.log('[Episodic] ğŸ“Š Chat ID:', chatId);
  
  try {
    // Verifica se chat jÃ¡ tem memÃ³ria
    console.log('[Episodic] ğŸ” Verificando se chat jÃ¡ possui memÃ³ria...');
    const existing = await episodicMemory.get(chatId);
    
    // Extrai evento estruturado da interaÃ§Ã£o atual
    const event = narrativeEngine.extractEvent(
      rawInteraction.userMessage,
      rawInteraction.aiResponse,
      { category: episodicData.categoria_principal || 'geral' }
    );
    
    console.log('[Episodic] ğŸ¯ Evento extraÃ­do:', event);
    
    let narrative = '';
    let events = [event];
    
    if (existing) {
      console.log('[Episodic] âœï¸ Chat possui memÃ³ria existente, atualizando...');
      
      // Recupera eventos anteriores (se estiverem armazenados)
      if (existing.episodicMemory.events) {
        events = [...existing.episodicMemory.events, event];
      }
      
      // ReconstrÃ³i narrativa completa com limite de 750 palavras
      narrative = narrativeEngine.eventsToNarrative(events, 750);
      
      console.log('[Episodic] ğŸ“ Narrativa atualizada:', {
        total_events: events.length,
        palavras: narrative.split(' ').length
      });
      
      // Atualiza memÃ³ria com evento + narrativa compacta
      const updatedData = {
        ...episodicData,
        narrative_summary: narrative,
        events: events.slice(-20), // mantÃ©m Ãºltimos 20 eventos estruturados
        last_interaction: new Date().toISOString()
      };
      
      await episodicMemory.update(chatId, updatedData, {
        merge: true,
        autoCompress: true
      });
      
      console.log('[Episodic] âœ… MemÃ³ria atualizada com sucesso');
      return { type: 'episodic', status: 'updated', chatId, events_count: events.length };
      
    } else {
      console.log('[Episodic] ğŸ†• Chat sem memÃ³ria, criando nova...');
      
      // Cria narrativa inicial
      narrative = narrativeEngine.eventsToNarrative([event], 750);
      
      // Cria nova memÃ³ria com evento + narrativa
      const initialData = {
        ...episodicData,
        narrative_summary: narrative,
        events: [event],
        created_at: new Date().toISOString(),
        last_interaction: new Date().toISOString()
      };
      
      await episodicMemory.create(chatId, userId, initialData);
      
      console.log('[Episodic] âœ… Nova memÃ³ria criada com sucesso');
      return { type: 'episodic', status: 'created', chatId, events_count: 1 };
    }
    
  } catch (error) {
    console.error('[Episodic] âŒ Erro no processamento:', error.message);
    return { type: 'episodic', status: 'error', error: error.message };
  }
}

/**
 * Processar Long-Term Memory
 */
async function processLongTermMemory(userId, chatId, longTermData) {
  console.log('[LongTerm] ğŸš€ INÃCIO - Processando Long-Term Memory');
  console.log('[LongTerm] ğŸ“Š Total de candidatos:', longTermData.length);
  console.log('[LongTerm] ğŸ“¦ Candidatos:', longTermData);
  
  const results = [];
  for (const item of longTermData) {
    console.log('[LongTerm] ğŸ¯ Propondo memÃ³ria:', {
      category: item.category,
      content: item.content.substring(0, 100) + '...',
      reason: item.reason
    });
    
    try {
      const stored = await longTermMemory.propose(
        userId,
        item.content,
        item.category,
        [chatId]
      );
      
      if (stored) {
        console.log('[LongTerm] âœ… MemÃ³ria ACEITA e armazenada');
        console.log('[LongTerm] ğŸ“Š Impact Score:', stored.impactScore);
        results.push({ 
          category: item.category, 
          status: 'accepted',
          impactScore: stored.impactScore 
        });
      } else {
        console.log('[LongTerm] âŒ MemÃ³ria REJEITADA pela curadoria');
        results.push({ 
          category: item.category, 
          status: 'rejected',
          reason: 'NÃ£o passou na curadoria'
        });
      }
      
    } catch (error) {
      console.error('[LongTerm] âŒ Erro ao propor memÃ³ria:', error.message);
      results.push({ 
        category: item.category, 
        status: 'error', 
        error: error.message 
      });
    }
  }
  
  console.log('[LongTerm] âœ… FIM - Long-Term Memory processada');
  console.log('[LongTerm] ğŸ“Š Resultados:', results);
  return { type: 'longTerm', results };
}

module.exports = {
  processMemories,
  classifyInteraction: patternClassifier.classifyInteraction
};