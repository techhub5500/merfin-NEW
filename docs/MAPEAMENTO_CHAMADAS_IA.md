# üìä Mapeamento Completo de Chamadas de IA no Sistema

**Gerado em:** 25/01/2026  
**Objetivo:** Documentar todas as chamadas de IA (LLM) no projeto, seus prop√≥sitos, par√¢metros e integra√ß√£o.

---

## üìã √çndice

1. [Resumo Executivo](#resumo-executivo)
2. [Wrappers/Configura√ß√µes de IA](#wrappersconfigura√ß√µes-de-ia)
3. [Chamadas por M√≥dulo](#chamadas-por-m√≥dulo)
4. [An√°lise de Tokens e Custos](#an√°lise-de-tokens-e-custos)
5. [Fluxo de Execu√ß√£o](#fluxo-de-execu√ß√£o)

---

## üéØ Resumo Executivo

### Total de Chamadas Identificadas: **12 pontos de invoca√ß√£o**

| M√≥dulo | Chamadas | Modelo Principal | Tokens Estimados/Chamada |
|--------|----------|------------------|--------------------------|
| **Junior Agent** | 1 | gpt-5-nano | 800 (output) + reasoning |
| **Memory Processing** | 1 | gpt-4.1-nano | 1000 |
| **Working Memory** | 1 | gpt-4.1-nano | 200 |
| **Episodic Memory** | 2 | gpt-4.1-nano | 600 + 200 |
| **Long-Term Memory** | 5 | gpt-4.1-nano | 200-800 |
| **Shared Utilities** | 2 | gpt-4.1-nano | Mock (n√£o configurado) |

---

## üîß Wrappers/Configura√ß√µes de IA

### 1. **openai-config.js** (Principal)
**Localiza√ß√£o:** `server/src/config/openai-config.js`

#### Fun√ß√µes Exportadas:
```javascript
callOpenAI(systemPrompt, userPrompt, options)
callOpenAIJSON(systemPrompt, userPrompt, options)
```

#### Configura√ß√£o:
- **Modelo:** `gpt-4.1-nano`
- **API Key:** `process.env.OPENAI_API_KEY`
- **Par√¢metros Padr√£o:**
  - `temperature: 0.3` (baixa para consist√™ncia)
  - `max_tokens: 1000`
  - `top_p: 0.95`
  - `frequency_penalty: 0.0`
  - `presence_penalty: 0.0`
- **Timeout:** 30 segundos
- **Retries:** 3 tentativas com delay de 1s entre elas

#### Comportamento:
1. `callOpenAI`: Retorna string de texto
2. `callOpenAIJSON`: 
   - Adiciona instru√ß√£o para retornar JSON v√°lido
   - Remove markdown code blocks (```json)
   - Parseia e retorna objeto JavaScript
   - Lan√ßa erro se JSON inv√°lido

#### Uso:
- **TODOS os m√≥dulos de mem√≥ria** usam este wrapper
- Importado via: `const { callOpenAI, callOpenAIJSON } = require('../../../config/openai-config')`

---

### 2. **deepseek-config.js** (Alternativo - N√£o Usado)
**Localiza√ß√£o:** `server/src/config/deepseek-config.js`

#### Status: **DEPRECADO / N√ÉO UTILIZADO**
- Configurado para usar DeepSeek v3 Chat
- API Key: `process.env.DEEPSEEK_API_KEY`
- Modelo: `deepseek-chat`
- **NOTA:** openai-config.js exporta aliases `callDeepSeek` e `callDeepSeekJSON` que redirecionam para OpenAI

---

## üì° Chamadas por M√≥dulo

---

## 1Ô∏è‚É£ JUNIOR AGENT (Resposta ao Usu√°rio)

### **1.1. Gera√ß√£o de Resposta Principal**
**Arquivo:** `server/src/agents/junior/junior/junior-agent.js`  
**Linha:** ~113  
**Fun√ß√£o:** `processChatMessage()`

#### Chamada:
```javascript
const response = await openai.responses.create({
  model: this.model,
  input: contextualInput,
  max_output_tokens: this.max_output_tokens,
  reasoning: { effort: this.reasoning_effort },
});
```

#### Par√¢metros Atuais:
- **Modelo:** `gpt-5-nano`
- **max_output_tokens:** `800` (aumentado de 320)
- **reasoning.effort:** `'medium'` (mudado de 'low')

#### Input (contextualInput):
Constru√≠do com:
1. **System Prompt:**
   ```
   Voc√™ √© um assistente financeiro prestativo. Responda de forma 
   clara, objetiva e concisa em portugu√™s brasileiro.
   ```

2. **Contexto de Mem√≥ria:** (se dispon√≠vel)
   - Working Memory
   - Episodic Memory
   - Long-Term Memory
   - Formatado via `memoryIntegration.formatContextForPrompt()`

3. **Hist√≥rico da Conversa:**
   ```
   Hist√≥rico da conversa:
   Usu√°rio: <mensagem1>
   Assistente: <resposta1>
   ...
   ```

4. **Mensagem Atual:**
   ```
   Usu√°rio: <mensagem>
   
   Assistente:
   ```

#### Output:
- Texto da resposta (extra√≠do via `_extractResponseText()`)
- Se vazio, retorna: "Desculpe, n√£o consegui gerar uma resposta."

#### Frequ√™ncia:
- **TODA mensagem do usu√°rio** dispara esta chamada

#### Custo Estimado:
- Input: ~500-2000 tokens (depende do contexto e hist√≥rico)
- Output: at√© 800 tokens
- Reasoning: vari√°vel (medium effort)

---

## 2Ô∏è‚É£ MEMORY PROCESSING (Classifica√ß√£o)

### **2.1. Classifica√ß√£o de Intera√ß√£o**
**Arquivo:** `server/src/core/memory/shared/memory-processor.js`  
**Linha:** ~185  
**Fun√ß√£o:** `classifyInteraction()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, {
  max_tokens: 1000,
  temperature: 0.3
});
```

#### System Prompt:
```
Voc√™ √© um classificador de mem√≥rias para sistema financeiro.
Analise a intera√ß√£o usu√°rio-IA e classifique informa√ß√µes para armazenamento.

TIPOS DE MEM√ìRIA:
1. WORKING MEMORY (tempor√°ria, sess√£o atual)
2. EPISODIC MEMORY (contexto do chat)
3. LONG-TERM MEMORY (perfil permanente)

CATEGORIAS LONG-TERM:
- perfil_profissional
- situacao_financeira
- investimentos
- objetivos_metas
- comportamento_gastos
- perfil_risco
- conhecimento_financeiro
- planejamento_futuro
- familia_dependentes
- relacao_plataforma
```

#### User Prompt:
```
Classifique esta intera√ß√£o:

MENSAGEM DO USU√ÅRIO: <userMessage>
RESPOSTA DA IA: <aiResponse>
HIST√ìRICO (√∫ltimas 3 mensagens): <history>

Retorne JSON:
{
  "working": [
    { "key": "nome_variavel", "value": "valor", "reason": "..." }
  ],
  "episodic": {
    "contexto_conversa": "resumo (primeira pessoa)",
    "preferencias_mencionadas": "...",
    "decisoes_tomadas": "..."
  },
  "longTerm": [
    {
      "content": "informa√ß√£o usando nome do usu√°rio",
      "category": "categoria v√°lida",
      "reason": "..."
    }
  ]
}
```

#### Output Esperado:
- `working`: Array de objetos {key, value, reason}
- `episodic`: Objeto com campos contextuais
- `longTerm`: Array de candidatos com category

#### Frequ√™ncia:
- **1 vez por mensagem** (ap√≥s JuniorAgent responder)
- Executado em background (n√£o bloqueia resposta)

#### Custo Estimado:
- Input: ~300-800 tokens
- Output: at√© 1000 tokens

---

## 3Ô∏è‚É£ WORKING MEMORY (Curadoria)

### **3.1. Valida√ß√£o de Entrada**
**Arquivo:** `server/src/core/memory/working/working-memory.js`  
**Linha:** ~66  
**Fun√ß√£o:** `_curateValue()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, { 
  max_tokens: 200,
  temperature: 0.2
});
```

#### System Prompt:
```
You are a working memory curator for a financial investment system.
Validate if this data should be stored in temporary working memory.

REJECT if:
- Contains sensitive data (passwords, API keys, tokens, CPF, credit cards, CVV)
- Is irrelevant noise or spam
- Is duplicate/redundant information

ACCEPT if:
- User's first name or nickname (for personalization)
- Temporary calculation results
- Intermediate processing data
- Current session context
- User preferences for current action
- Financial analysis intermediate results

IMPORTANT: First names like "John", "Maria", "Edmar" are OK.
```

#### User Prompt:
```
Validate this working memory entry:

Key: "<key>"
Value: <value as JSON>

Return JSON:
{
  "allowed": <true/false>,
  "reason": "<brief explanation>",
  "sanitizedValue": <cleaned value or original>
}
```

#### Output Esperado:
- `allowed`: boolean
- `reason`: string
- `sanitizedValue`: valor limpo/original

#### Frequ√™ncia:
- Para **cada item de working memory** identificado pela classifica√ß√£o
- Pode ser skipped com par√¢metro `skipCuration=true`

#### Custo Estimado:
- Input: ~100-200 tokens
- Output: at√© 200 tokens

---

## 4Ô∏è‚É£ EPISODIC MEMORY (Curadoria e Relev√¢ncia)

### **4.1. Curadoria de Conte√∫do**
**Arquivo:** `server/src/core/memory/episodic/episodic-memory.js`  
**Linha:** ~63  
**Fun√ß√£o:** `_curateContent()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, { 
  max_tokens: 600,
  temperature: 0.2
});
```

#### System Prompt:
```
You are an episodic memory curator for a financial investment system.
Validate and sanitize content before storing in chat-specific memory.

REJECT ONLY if:
- Contains passwords or API keys
- Contains CPF (format: XXX.XXX.XXX-XX or 11 digits)
- Contains credit card numbers (16 digits)
- Contains other document numbers (RG, CNH, passport)
- Contains spam or malicious content

ACCEPT (these are OK):
- Salary information and income values
- Investment amounts and financial data
- User preferences and personal information
- Financial analysis and insights
- Conversation context
```

#### User Prompt:
```
Curate this episodic memory content for chat <chatId>:

<content as JSON>

Return JSON:
{
  "allowed": <true/false>,
  "reason": "<brief explanation>",
  "sanitizedContent": <cleaned version>
}
```

#### Output Esperado:
- `allowed`: boolean
- `reason`: string explicativo
- `sanitizedContent`: objeto limpo

#### Frequ√™ncia:
- **1 vez ao criar** nova episodic memory
- **1 vez ao atualizar** episodic memory existente

#### Custo Estimado:
- Input: ~200-400 tokens
- Output: at√© 600 tokens

---

### **4.2. Scoring de Relev√¢ncia (Fragmentos)**
**Arquivo:** `server/src/core/memory/episodic/relevance-scorer.js`  
**Linha:** ~47  
**Fun√ß√£o:** `scoreFragment()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, { 
  max_tokens: 200 
});
```

#### System Prompt:
```
You are a memory relevance analyzer for a financial investment system.
Evaluate how relevant and important a memory fragment is.

Consider:
1. Strategic value
2. Specificity
3. Uniqueness
4. Future utility
5. Recency context (weight: <recency>)
```

#### User Prompt:
```
Score this memory fragment's relevance (0.0 to 1.0):

Fragment: "<fragment>"
Keywords to consider: <keywords>
Chat context: <chatContext>

Return JSON:
{
  "score": <0.0-1.0>,
  "reasoning": "<brief explanation>"
}
```

#### Output Esperado:
- `score`: n√∫mero entre 0 e 1
- `reasoning`: explica√ß√£o breve

#### Frequ√™ncia:
- Usado pelo **compression-engine** durante compress√£o
- N√£o chamado automaticamente em toda intera√ß√£o

#### Custo Estimado:
- Input: ~100-200 tokens
- Output: at√© 200 tokens

---

### **4.3. Prioriza√ß√£o de Informa√ß√µes**
**Arquivo:** `server/src/core/memory/episodic/relevance-scorer.js`  
**Linha:** ~101  
**Fun√ß√£o:** `prioritizeInformation()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, { 
  max_tokens: 500 
});
```

#### System Prompt:
```
You are a memory prioritization system for financial investments.
Identify which pieces of information are most valuable to keep.

Prioritize:
- Investment strategies and patterns
- User preferences and risk tolerance
- Important financial decisions
- Unique behavioral patterns
```

#### User Prompt:
```
Prioritize this memory data. Keep only the <targetCount> most important items.

Memory data: <memory as JSON>
Context: <chatContext>

Return JSON:
{
  "prioritized": { <same structure with only important items> },
  "reasoning": "<brief explanation of what was kept>"
}
```

#### Output Esperado:
- `prioritized`: objeto filtrado
- `reasoning`: justificativa

#### Frequ√™ncia:
- Usado durante **compress√£o avan√ßada**
- N√£o executado automaticamente

#### Custo Estimado:
- Input: ~200-500 tokens
- Output: at√© 500 tokens

---

## 5Ô∏è‚É£ LONG-TERM MEMORY (Curadoria, Impacto e Refinamento)

### **5.1. C√°lculo de Impact Score**
**Arquivo:** `server/src/core/memory/longTerm/relevance-calculator.js`  
**Linha:** ~64  
**Fun√ß√£o:** `calculate()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, { 
  max_tokens: 400 
});
```

#### System Prompt:
```
You are a memory impact evaluator for a financial investment system.
Analyze memory content and calculate an impact score (0.0 to 1.0).

Factors:
1. RECURRENCE (25%): How often mentioned/accessed?
2. STRUCTURALITY (30%): Impact on finances, decisions, strategies?
3. DURABILITY (20%): Long-term relevant or temporary?
4. SPECIFICITY (15%): Concrete and specific vs vague?
5. ACTIONABILITY (10%): Can lead to concrete actions?

Higher scores (>0.7) = worthy of permanent storage
Lower scores (<0.5) = disposable/low-value
```

#### User Prompt:
```
Evaluate this memory for long-term storage:

Content: "<content>"

Context:
- Access count: <accessCount>
- Mentioned in <sourceChats.length> different chats
- Total mentions: <mentionCount>
- Category: <category>
- Age: <days> days old

Analyze each factor and return JSON:
{
  "factors": {
    "recurrence": <0.0-1.0>,
    "structurality": <0.0-1.0>,
    "durability": <0.0-1.0>,
    "specificity": <0.0-1.0>,
    "actionability": <0.0-1.0>
  },
  "overallScore": <0.0-1.0>,
  "reasoning": "<brief explanation>"
}
```

#### Output Esperado:
- `factors`: objeto com 5 scores
- `overallScore`: score final
- `reasoning`: explica√ß√£o

#### P√≥s-processamento:
```javascript
// Calcula score ponderado
calculatedScore = 
  factors.recurrence * 0.25 +
  factors.structurality * 0.30 +
  factors.durability * 0.20 +
  factors.specificity * 0.15 +
  factors.actionability * 0.10
```

#### Frequ√™ncia:
- **1 vez por candidato de LTM** durante curadoria
- Threshold: score >= 0.7 para admiss√£o

#### Custo Estimado:
- Input: ~200-300 tokens
- Output: at√© 400 tokens

#### Fallback:
- Se falhar, usa algoritmo local baseado em keywords

---

### **5.2. Refinamento de Conte√∫do**
**Arquivo:** `server/src/core/memory/longTerm/memory-curator.js`  
**Linha:** ~132  
**Fun√ß√£o:** `refineWithLLM()`

#### Chamada:
```javascript
const refined = await callOpenAI(systemPrompt, userPrompt, {
  max_tokens: 200,
  temperature: 0.3
});
```

#### System Prompt:
```
You are a memory curator for a financial investment system.
Refine memories for long-term storage by keeping only essential information.

Guidelines:
- Preserve key facts, preferences, and strategic information
- Remove noise, redundancy, and temporary details
- Keep actionable insights and patterns
- Maintain clarity and specificity
- Identify event date (or use today if unclear)
- Memory MUST start with "Em DD/MM/YYYY, " prefix
- Maximum 60 words (including date)
```

#### User Prompt:
```
Refine this memory for long-term storage:

Category: <category>
Impact Score: <impactScore>
Original: <content>

MANDATORY FORMAT:
- Start with "Em DD/MM/YYYY, "
- Follow with refined content
- Total max 60 words

Return refined version:
```

#### Output Esperado:
- String com mem√≥ria refinada (max 60 palavras)
- Formato: "Em DD/MM/YYYY, [conte√∫do refinado]"

#### Frequ√™ncia:
- **1 vez por mem√≥ria aceita** (impact >= 0.7)
- Ap√≥s refinamento, pode ser comprimida se > 60 palavras

#### Custo Estimado:
- Input: ~100-200 tokens
- Output: at√© 200 tokens

---

### **5.3. Extra√ß√£o de Alto Impacto (Episodic ‚Üí LTM)**
**Arquivo:** `server/src/core/memory/longTerm/memory-curator.js`  
**Linha:** ~194  
**Fun√ß√£o:** `extractHighImpact()`

#### Chamada:
```javascript
const result = await callOpenAIJSON(systemPrompt, userPrompt, {
  max_tokens: 800,
  temperature: 0.4
});
```

#### System Prompt:
```
Voc√™ √© um extrator de mem√≥rias de longo prazo para sistema financeiro.
Analise a mem√≥ria epis√≥dica e extraia informa√ß√µes de ALTO IMPACTO.

IMPORTANTE: Use sempre o NOME DO USU√ÅRIO ao formular mem√≥rias.
NOME DO USU√ÅRIO: <userName>

CATEGORIAS DISPON√çVEIS:
[lista de categorias com descri√ß√µes]

Para cada informa√ß√£o valiosa:
1. Identifique a categoria apropriada
2. Formule usando o NOME do usu√°rio
3. Seja espec√≠fico com valores e datas
4. Avalie impact score (0.0-1.0)

Extraia apenas informa√ß√µes que:
- Sejam duradouras e relevantes
- Tenham impacto em decis√µes futuras
- Sejam espec√≠ficas e acion√°veis
- Mere√ßam armazenamento permanente (score >= 0.7)
```

#### User Prompt:
```
Extract high-impact information from this episodic memory:

<episodicData as JSON>

Return JSON array of candidates com o nome "<userName>":
[
  {
    "content": "<extracted information usando '<userName>'>",
    "category": "<categoria v√°lida>",
    "reasoning": "<why this is high-impact>"
  }
]
```

#### Output Esperado:
- Array de objetos: `{content, category, reasoning}`
- Cada candidate √© avaliado posteriormente com `calculate()`

#### Frequ√™ncia:
- Chamado quando **episodic memory tem alto impacto**
- N√£o autom√°tico - requer trigger manual ou threshold

#### Custo Estimado:
- Input: ~300-600 tokens
- Output: at√© 800 tokens

---

### **5.4. Atualiza√ß√£o de Descri√ß√£o de Categoria**
**Arquivo:** `server/src/core/memory/longTerm/category-description-updater.js`  
**Linha:** ~51  
**Fun√ß√£o:** `updateCategoryDescription()`

#### Chamada:
```javascript
let description = await callOpenAI(systemPrompt, userPrompt, {
  temperature: 0.3,
  max_tokens: 150
});
```

#### System Prompt:
```
Voc√™ √© um assistente financeiro que cria descri√ß√µes concisas de perfil.
Siga EXATAMENTE as regras fornecidas.
```

#### User Prompt:
```
Voc√™ √© um assistente financeiro especializado em criar descri√ß√µes concisas.

CATEGORIA: <category>

MEM√ìRIAS NA CATEGORIA:
1. <memory1>
2. <memory2>
...

TAREFA:
Crie uma descri√ß√£o de NO M√ÅXIMO 25 PALAVRAS que resuma o perfil.

REGRAS OBRIGAT√ìRIAS:
1. M√°ximo 25 palavras
2. SEM datas espec√≠ficas
3. SEM valores monet√°rios detalhados
4. SEM nomes de ativos espec√≠ficos
5. Foco em PADR√ïES e CARACTER√çSTICAS gerais
6. Linguagem objetiva e profissional
7. Terceira pessoa (sem "o usu√°rio")

EXEMPLOS DE BOAS DESCRI√á√ïES:
- "Investidor conservador com portf√≥lio diversificado em renda fixa, 
   prioriza liquidez e seguran√ßa"

RETORNE APENAS A DESCRI√á√ÉO, SEM EXPLICA√á√ïES.
```

#### Output Esperado:
- String de at√© 25 palavras
- Sem datas, valores espec√≠ficos, nomes de ativos

#### P√≥s-processamento:
```javascript
// Remove aspas
description = description.replace(/^["']|["']$/g, '');

// Trunca se exceder 25 palavras
if (countWords(description) > 25) {
  description = truncateToWords(description, 25);
}
```

#### Frequ√™ncia:
- **Ap√≥s cada propose() bem-sucedido** em LTM
- Atualiza a descri√ß√£o din√¢mica da categoria

#### Custo Estimado:
- Input: ~150-300 tokens (depende do n√∫mero de mem√≥rias)
- Output: at√© 150 tokens

---

### **5.5. Fus√£o de Mem√≥rias (Memory Merger)**
**Arquivo:** `server/src/core/memory/longTerm/memory-merger.js`  
**Linha:** ~108  
**Fun√ß√£o:** `fuseMemories()` (comentado/futuro)

#### Status: **N√ÉO IMPLEMENTADO (TODO)**

#### Chamada Planejada:
```javascript
const response = await openai.chat.completions.create({
  model: 'gpt-4',
  messages: [{ role: 'user', content: prompt }],
  max_tokens: 150,
  temperature: 0.3
});
```

#### Prompt Planejado:
```
Merge these two related memories into one concise memory:
Memory 1: <existing>
Memory 2: <newContent>

Merged memory (preserve all unique information, max 100 words):
```

#### Implementa√ß√£o Atual:
- Usa deduplica√ß√£o de frases baseada em Set
- LLM fusion est√° comentada para implementa√ß√£o futura

---

## 6Ô∏è‚É£ SHARED UTILITIES (Embedding - N√£o Configurado)

### **6.1. Gera√ß√£o de Embeddings**
**Arquivo:** `server/src/core/memory/shared/embedding-generator.js`  
**Linha:** ~18  
**Fun√ß√£o:** `generate()`

#### Status: **N√ÉO CONFIGURADO (MOCK)**

#### Chamada Planejada (Comentada):
```javascript
// TODO: Integrate with actual OpenAI SDK
// const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
// const response = await openai.embeddings.create({
//   model: 'text-embedding-3-small',
//   input: text
// });
// return response.data[0].embedding;
```

#### Implementa√ß√£o Atual:
```javascript
// Placeholder: return mock embedding
console.warn('[EmbeddingGenerator] Using MOCK embeddings');
return new Array(1536).fill(0).map(() => Math.random());
```

#### Impacto:
- **Semantic search N√ÉO funciona corretamente**
- Memory merger similarity N√ÉO √© precisa
- Vector store usa embeddings aleat√≥rios

#### Para Ativar:
1. Configurar `OPENAI_API_KEY` em .env
2. Instalar: `npm install openai`
3. Descomentar c√≥digo

---

### **6.2. Gera√ß√£o de Embeddings em Lote**
**Arquivo:** `server/src/core/memory/shared/embedding-generator.js`  
**Linha:** ~47  
**Fun√ß√£o:** `generateBatch()`

#### Status: **N√ÉO CONFIGURADO (MOCK)**

#### Chamada Planejada (Comentada):
```javascript
// const response = await openai.embeddings.create({
//   model: 'text-embedding-3-small',
//   input: texts
// });
// return response.data.map(item => item.embedding);
```

#### Implementa√ß√£o Atual:
- Retorna array de embeddings mock (aleat√≥rios)

---

## üìä An√°lise de Tokens e Custos

### Cen√°rio T√≠pico: Mensagem do Usu√°rio

#### Fluxo Completo:
1. **JuniorAgent.processChatMessage()**
   - Input: ~500-2000 tokens (contexto + hist√≥rico + mensagem)
   - Output: ~800 tokens (resposta)
   - Reasoning tokens: vari√°vel (medium effort)
   - **Custo:** ~2800 tokens TOTAL

2. **MemoryProcessor.classifyInteraction()** (background)
   - Input: ~300-800 tokens
   - Output: ~1000 tokens
   - **Custo:** ~1800 tokens TOTAL

3. **WorkingMemory._curateValue()** (para cada item working)
   - Input: ~100-200 tokens
   - Output: ~200 tokens
   - **Custo por item:** ~400 tokens
   - Se 2 itens: ~800 tokens TOTAL

4. **EpisodicMemory._curateContent()** (1x)
   - Input: ~200-400 tokens
   - Output: ~600 tokens
   - **Custo:** ~1000 tokens TOTAL

5. **RelevanceCalculator.calculate()** (para cada candidato LTM)
   - Input: ~200-300 tokens
   - Output: ~400 tokens
   - **Custo por candidato:** ~700 tokens
   - Se 1 candidato: ~700 tokens TOTAL

6. **MemoryCurator.refineWithLLM()** (se candidato aceito)
   - Input: ~100-200 tokens
   - Output: ~200 tokens
   - **Custo:** ~400 tokens TOTAL

7. **CategoryDescriptionUpdater.updateCategoryDescription()** (ap√≥s propose)
   - Input: ~150-300 tokens
   - Output: ~150 tokens
   - **Custo:** ~450 tokens TOTAL

### **TOTAL ESTIMADO POR MENSAGEM:**
- **M√≠nimo (sem LTM):** ~5600 tokens
- **M√©dio (1 LTM candidate):** ~7150 tokens
- **M√°ximo (m√∫ltiplos candidates + compression):** ~10000+ tokens

---

## üîÑ Fluxo de Execu√ß√£o

### Diagrama de Sequ√™ncia:

```
Usu√°rio envia mensagem
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. JUNIOR AGENT                             ‚îÇ
‚îÇ    - Carrega contexto de mem√≥ria            ‚îÇ
‚îÇ    - Constr√≥i prompt com hist√≥rico          ‚îÇ
‚îÇ    - openai.responses.create()              ‚îÇ ‚Üê LLM #1 (gpt-5-nano)
‚îÇ    - Retorna resposta ao usu√°rio            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì (em paralelo, background)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. MEMORY PROCESSOR                         ‚îÇ
‚îÇ    - classifyInteraction()                  ‚îÇ ‚Üê LLM #2 (gpt-4.1-nano)
‚îÇ    - Identifica: working, episodic, longTerm‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
    ‚îú‚îÄ‚Üí [WORKING MEMORY]
    ‚îÇ   Para cada item working:
    ‚îÇ   - _curateValue()                       ‚Üê LLM #3 (gpt-4.1-nano)
    ‚îÇ   - Valida e armazena
    ‚îÇ
    ‚îú‚îÄ‚Üí [EPISODIC MEMORY]
    ‚îÇ   - _curateContent()                     ‚Üê LLM #4 (gpt-4.1-nano)
    ‚îÇ   - create() ou update()
    ‚îÇ   - Auto-compress se necess√°rio
    ‚îÇ
    ‚îî‚îÄ‚Üí [LONG-TERM MEMORY]
        Para cada candidato:
        - relevanceCalculator.calculate()      ‚Üê LLM #5 (gpt-4.1-nano)
        - Se score >= 0.7:
          - memoryCurator.refineWithLLM()      ‚Üê LLM #6 (gpt-4.1-nano)
          - propose() ‚Üí armazena
          - updateCategoryDescription()        ‚Üê LLM #7 (gpt-4.1-nano)
```

---

## üéØ Recomenda√ß√µes de Otimiza√ß√£o

### 1. **Reduzir Chamadas em Cadeia**
   - Considerar batch processing para m√∫ltiplos candidatos LTM
   - Cache de classifica√ß√µes similares

### 2. **Ajustar max_tokens**
   - **JuniorAgent:** 800 tokens √© adequado (ajustado recentemente)
   - **Classification:** 1000 tokens pode ser reduzido para 600
   - **Curation:** 600 tokens pode ser reduzido para 400

### 3. **Fallbacks Inteligentes**
   - Todos os m√≥dulos j√° t√™m fallbacks algor√≠tmicos
   - Considerar usar fallback ap√≥s 2 falhas consecutivas

### 4. **Configurar Embeddings**
   - **CR√çTICO:** Embeddings est√£o usando MOCK
   - Ativar OpenAI embeddings para semantic search real

### 5. **Monitoramento de Custos**
   - Adicionar contador de tokens total por sess√£o
   - Alert se exceder threshold (ex: 50k tokens/dia por usu√°rio)

---

## üìù Notas Finais

### Modelos Utilizados:
- **gpt-5-nano:** Apenas para JuniorAgent (resposta ao usu√°rio)
- **gpt-4.1-nano:** Todos os outros processos de mem√≥ria
- **text-embedding-3-small:** Planejado (n√£o configurado)

### Depend√™ncias:
- `openai` SDK (Node.js)
- `axios` (para DeepSeek - n√£o usado)

### Vari√°veis de Ambiente Necess√°rias:
```env
OPENAI_API_KEY=sk-...
DEEPSEEK_API_KEY=sk-...  # Opcional, n√£o usado atualmente
```

### Arquivos Chave:
1. `server/src/config/openai-config.js` - Wrapper principal
2. `server/src/agents/junior/junior/junior-agent.js` - Resposta ao usu√°rio
3. `server/src/core/memory/shared/memory-processor.js` - Orquestra√ß√£o
4. `server/src/core/memory/*/` - M√≥dulos de mem√≥ria com IA

---

**Documento gerado automaticamente via an√°lise de c√≥digo.**  
**√öltima atualiza√ß√£o:** 25/01/2026  
**Vers√£o:** 1.0
